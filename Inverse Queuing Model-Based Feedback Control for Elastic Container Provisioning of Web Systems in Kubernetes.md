# Inverse Queuing Model-Based Feedback Control for Elastic Container Provisioning of Web Systems in Kubernetes  
# (基于逆向排队模型的反馈控制用于Kubernetes中网络系统的弹性容器供应)  

## Abstract
&emsp;&emsp;容器编排平台，例如Kubernetes和Kubernetes的派生 KubeEdge等已经逐步用于云计算、雾计算和边缘计算资源的统一管理。为了保证基于Kubernetes系统的服务质量(QoS)，容器供应算法时至关重要的。然而，大多数现有算法侧重于配置和迁移固定数量的容器，未考虑容器的弹性供应。同时，广泛应用基于线性性能模型的反馈控制或基于固定处理速率的排队模型在不同平台上无法准确描述容器化Web系统的性能。此外，在现有方法中使用的固定参考点在到达率变化较大时会产生巨大的波动，很可能产生不准确的输出误差。在这篇文章中，设计了一种基于变处理率排队模型和线性模型相结合的反馈控制方法，通过学习不同到达率的参考模型，并将参考模型的输出误差映射到排队模型，提高输出误差的准确性。在一个真实的Kubernetes集群上，将我们的算法与几种最先进的算法进行比较。实验结果表明，我们的方法获得了最低的服务水平协议(SLA)违反百分比(至少降低8.44%)和第二的最低成本。
## 1 Introduction
&emsp;&emsp;共享私有数据中心等不同系统资源最有效的方法之一就是云计算、雾计算和边缘计算在不同应用程序中正在使用的更轻量级的、比VM更容易移植的容器。Kubernetes是一种流行的容器编排系统，并逐步用于管理云计算、雾计算和边缘计算的容器资源，并导致许多衍生平台的出现，例如KubeEdge。Kubernetes的不同应用程序的Pod(一个或多个容器组成)被部署在从公共云租用的虚拟机或雾和边缘节点的物理机（PM）上。同时，网络应用和服务(统称为网络系统)在云计算、雾计算和边缘计算中非常普遍，通过以容器形式部署的不同微服务中，向终端用户提供各种功能。其中最关键的一个问题是设计容器自动缩放算法来控制基于Kubernetes的平台中每一个微服务的响应时间。  
&emsp;&emsp;大多现有容器供应算法侧重于部署和迁移虚拟机和物理机中固定数目的容器而不是容器的自动缩放。但是，分配给每一个微服务的容器数量对请求响应时间有很大的影响。Kubernetes内置的自动缩放设计和大多基于阈值的方法仅仅根据资源利用率增加或删除容器副本，而资源利用率是控制响应时间的间接指标。因此，本文的主要目标是为Kbernetes设计容器自缩放方法，自动调整给每个微服务分配的容器数量，减少资源浪费，同时保证服务质量。设计这种自缩放算法的主要挑战包括多容器系统的非线性性能模型和寻找合适的输出误差计算方法。  
&emsp;&emsp;Web系统的非线性性能特征使得资源自缩放变得复杂。QoS控制在传统Web系统中得到广泛研究，设计应用程序资源、物理机和虚拟机的弹性供应。但是，大多现有方法属于基于纯排队论的前馈控制和基于线性模型的反馈控制，这些方法缺乏反馈能力或无法准确描述复杂的非线性多容器系统。虽然，基于线性模型的反馈控制利用排队论和控制论结合的优势来修正排队模型的不准确性，但只有当系统在参考点附近时，参考点推导的线性模型才能取得良好的效果。  
&emsp;&emsp;参考点与实际响应时间之间的偏差称为输出误差，输出误差对控制性能具有很大的影响。选择合适的参考点计算输出误差有助于获得稳定的输出性能。在现有方法中，参考点通常是根据不同的到达率手动选择和保持不变。但是，一个固定的参考点有可能引起大的波动，因为不同到达率有不同的稳定工作点。同时，剖析的性能模型和真实系统之间的差异是不可避免的，这使得输出误差与剖析的性能模型不匹配。  
&emsp;&emsp;本文提出了一种基于逆排队模型的反馈控制方法在保证Kubernetes中容器化Web系统的QoS，降低了8.44%的SLA违反百分比。我们工作的主要贡献如下。  
&emsp;&emsp;1)提出一个基于变化处理率的排队模型和线性模型的混合模型，用来更准确地描述多容器系统的性能。逆排队模型用于线性化控制系统以简化控制器的设计。  
&emsp;&emsp;2)提出一个在线参考模型学习方法，为不同到达率找到适合的参考点以增加输出误差的准确度。  
&emsp;&emsp;3)提出了一种自适应输出误差映射方法，以修正采样参考模型和剖析性能模型之间的不一致，避免激烈的控制波动。  
&emsp;&emsp;本文的其余部分组织如下。第2节是相关的工作和第3节描述了Kubernetes中的web系统。第4节介绍了所提出的方法。第5节和第6节包括在一个真实的Kubernetes集群上的性能评估，结论和未来的工作。  
## 2 Related work  
&emsp;&emsp;大多数现有的容器调度工作都假设每个应用程序消耗的容器是固定的。在私有或弹性租用的底层资源上部署和迁移固定数量的容器可以被建模为一个装箱(bin-packing)问题并由CPLEX解决。对于Kubernetes，已经提出了启发式方法，如最佳拟合递减装箱(BFD)和time-bin BFD，用于容器的部署和迁移。考虑到雾计算节点的地理位置、用户移动性和违反SLA的能量消耗，强化学习和博弈论也被用于固定数目容器的部署和迁移。  
&emsp;&emsp;与分配固定数量的容器相比，提供可拓展的计算和存储能力给应用程序有助于节约资源成本和提高资源利用率。例如，[22]的作者提出了一个方案，通过细粒度的数据更新来支持云中的数据审计处理。相对于每一次小更新都需要重新计算和更新整个文件夹的固定大小的更新，它节省了大量的数据审计处理的存储和计算开销。该方案在云计算中提供了高度可伸缩的和高效的数据审计处理方法。为了给Kubernetes中的应用程序提供可伸缩的计算能力。假设每个应用程序都有一个性能下降的资源阈值，或者预先分析了为每个应用程序提供不同数量容器的效用，则使用遗传算法和线性规划在多个应用程序之间寻找最优的容器分配策略。换句话说，这些工作主要集中在竞争应用程序之间的资源分配上，而本文考虑的是一个应用程序的容器自动伸缩。由于传统应用资源的自动伸缩方法，可以通过迁移pm和vm来处理容器的自动伸缩，因此对自动伸缩技术进行了综述。  
### 2.1 QoS控制的自动伸缩  
&emsp;&emsp;阈值是最简单的自动缩放技术之一。Kubernetes内置的自动缩放调度程序根据CPU和内存使用率调账容器数量。当现有资源已经用完时，添加单个容器或者当实时响应时间远大于阈值时，添加固定数目的容器。基于阈值的方法难点在于如何选择适合不同到达率的阈值。  
&emsp;&emsp;排队模型描述了Web系统的平均响应时间、请求到达率和分配资源之间的关系。M/M/1、M/M/N、异构M/M/N排队模型和排队网络用于确保Web系统QoS的最小虚拟机或物理机的数量。然而，基于纯排队模型的方法缺少对实时输出误差作出反应的能力。  
&emsp;&emsp;反馈控制是应用程序资源自动伸缩的基本方法。基于线性性能模型的固定增益、自适应或多模型切换的反馈控制方法已经广泛应用于应用程序的自动缩放。一个比线性模型更加准确的反比例性能模型被用来设计一个反馈控制方法来自动缩放Web应用程序中的容器。排队模型比线性模型或反比例模型更加准确，并且被用于提升反馈控制的性能。例如，M/M/1排队模型派生出的线性模型被用来设计反馈控制器，描述了输出误差变化和参考点附近分配资源调整的线性关系，并且只在参考点附近取得良好效果。对于Kubernetes来说，基于M/M/1模型的反馈控制器被用来调整一个松散耦合M/M/N模型的到达率调整系数，这是为了避免因云计算虚拟机的基于时间间隔的收费模式所产生的过度控制而量身定制的。  
&emsp;&emsp;基于Q表和深度神经网络的强化学习被用来弹性分配Web系统的虚拟机或物理机。但是这种方法需要一个较长的采样和训练时间来获得良好的性能。因此，基于精准模型的方法仍是必要的，它可用来指导基于深度学习的方法。  
### 2.2 与现有算法对比  
&emsp;&emsp;表1展示了我们的方法与现有资源供应算法的比较。首先，现有的线性或排队模型派生的线性模型不能准确描述基于容器的系统的性能。相反，我们的方法采用了基于更精确的性能模型的反馈控制器，该模型是变化处理率M/M/N模型和线性模型的混合体。其次，大多数现有的工作都是使用通过经验获得的固定参考点来直接计算输出误差，然而我们采用了自动参考点识别方法和一个自适应输出误差映射方法来提高控制的稳定性。 最后，我们的方法是作为Kubernetes的用户级调度器而非模拟平台来实现的。 

<h4 align="center">表1 我们的方法与Web系统中现有资源供应算法对比</h4>  

|       Resources       |                       Problems                       |                          Objectives                          |                  Algorithms and Complexity                   |                          Platforms                           |
| :-------------------: | :--------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| Application Resources |                     Auto-scaling                     |        Absolute or relative<br>average response time         | Liner-model-based feedback<br>control,O(1)<br>Queuing-model-derived<br>liner model based<br>hybird control,O(n<sup>2</sup>) |           single WebServer<br><br>single WebServer           |
|      VMs or PMs       |                     Auto-scaling                     |                    Average response time                     | Threshold,O(1)<br>Reinforcement learning<br><br>Queuing models,O(n<sup>2</sup>)<br><br>Queuing-length-based feedback control,O(1)<br>Queuing-model-arrival-rate<br>adjusting-coefficient based<br>hybrid control, O(n2) | Private VM clusters<br>Private VM or PM clusters,<br>Public Clouds,MATLAB<br>Simulation,OpenStack,<br>Private VM clouds<br>CometCloud<br><br>CloudSim,Private VM<br>clusters |
|      Containers       | Fixed containers per application<br><br>Auto-scaling | Power consumption,etc<br>Deployment Cost of<br>VMs<br>Resource usage,<br>Average response<br>time<br>Total network<br>latency,etc<br>Average response<br>time | Deep Q-learning<br><br>CPLEX, BFD, Time-bin BFD,<br>Greedy algorithms<br>Threshold,O(1)<br><br><br>Threshold,Genetic algorithm<br><br>Simple non-liner model<br>based feedback control,O(1)<br>Inverse-M/M/N-model based<br>feedback control,O(n<sup>2</sup>) | Private VM clusters<br><br>Kubernetes,Simulation<br><br>IaaS,Docker Swarm<br><br><br>Simulation<br><br><br>ECOWARE<br><br>Kubernetes(Our) |
## 3 Kubernetes中的Web系统  

&emsp;&emsp;利用基于微服务的体系结构组织不同的Web系统，具有灵活性和互操作性。这类Web系统的每一层都可以实现为一个微服务，它们在并行容器中运行，以支持大规模请求。每一个微服务都提供一个功能，并且微服务通常本封装为一个RESTful或基于SOAP的Web服务。Kubernetes被广泛用于管理包含一个Mster节点和众多Work节点的容器，如图1所示。Pod是资源管理的基本单元，由一个或多个容器组成。微服务的容器嵌在部署在Worker节点(pm或vm)上的Pods中。相同颜色的容器属于同一个微服务。相同微服务的用户请求被nginx-ingress控制器分配到并行的容器中。通过Kubernetes中的java-client-interface检测每一个微服务的实时性能，在此基础上，容器自动扩展控制器（ASC）作为一个用户级插件来实现，为每个微服务分别分配适当数量的容器。每个微服务都有自己的ASC，即采用分散的控制方法。
&emsp;&emsp;平均响应时间和资源成本是容器化Web系统的两个关键指标。在微服务的SLA中，通常定义为k%的响应时间应小于给定的阈值Wsla。由于同一微服务通常需要相同的容器，一个容器单元（CU）被定义为在一个控制区间内将一个容器分配给一个微服务的成本。本文的目的是为ASCs设计容器弹性伸缩算法，以减少CU的消耗，同时保证SLAs。  

![image-20211126103952480](image/Inverse Queuing_FIG_1.png)

<center>图1  在Kubernetes中容器化Web系统的构造</center>

## 4 提出的反馈控制方法

&emsp;&emsp;在这篇文章中，提出了一个基于逆排队模型的反馈控制方法(Feedback_InverseQM)。首先采用了基于变化处理率的M/M/N模型和线性模型的混合模型来准确描述系统。然后开发了一种自动参考模型学习方法，以产生准确的输出误差。基于性能模型和输出误差，设计了一个基于逆排队模型的积分控制器。接下来研究了一种自适应输出误差映射方法，以修正采样参考模型和剖析排队模型之间的不一致。最后，在系统不稳定的情况下，使用基于排队长度的调度方法来提供容器。  

### 4.1 基于变化处理率的性能模型

&emsp;&emsp;性能模型是反馈控制的基础。在Kubernetes中，由于调度开销的原因，一个容器的平均处理率随着请求到达率的增加而下降。基于固定处理率的传统排队模型的性能模型不能准确描述系统。使λ作为请求到达率，N代表容器数量。在本文中，每一个容器的处理速率与到达率成反比：  

$$
\mu = \mu_{b} + c/\lambda
$$
&emsp; &emsp; $\mu$是基础变化速率，$c$是$\lambda$的反比例系数，根据现存的M/M/N模型，整个系统中没有请求的概率是
$$
P_{0}=[\sum^{N-1}_{k=0}\frac{1}{k!}(\frac{\lambda}{\mu})^k+\frac{\lambda^N}{N!(1-\frac{\lambda}{N\times\mu})\mu^N}]^{-1}
$$
&emsp; &emsp;等待队列中和正在处理的请求数量的期望值为
$$
L_{s}(N,\lambda,\mu) = \frac{(\frac{\lambda}{\mu})^N\frac{\lambda}{N\times\mu}}{N!(1-\frac{\lambda}{N\times\mu})^2}P_0+\frac{\lambda}{\mu}
$$
&emsp;&emsp;请求的平均响应时间的期望是
$$
W_s(N,\lambda,\mu) = \frac{L_s(N,\lambda,\mu)}{\lambda}
$$
&emsp;&emsp;同时，当前平均响应时间也受到过去数值的影响。因此，在本文中，控制步骤$k$的平均响应时间$y_k$被定义为过去值$y_{k-1}$和$W_s(N,\lambda,\mu)$的加权组合：
$$
y_k = a\times y_{k-1} + (1-a) \times W_s(N,\lambda,\mu)
$$
&emsp;&emsp;方程(5)是基于反比例处理率(变化的处理率)的M/M/N排队模型和线性模型的混合体，方程(5)被应用于本文的性能模型。

### 4.2 自动参考模型学习

&emsp;&emsp; 参考点对计算输出误差是至关重要的，它是反馈控制的基础。因为容器是以粗粒度配置的，所以当配置容器的数量被调整时，平均响应时间（称为稳定点）不能平稳变化，如图2所示。因此，给定的$W_{sla}$可能会离稳定点很远，并且直接使用$W_{sla}$作为参考点有可能造成大的波动应从小于$W_{sla}$的稳定点中选取合适的参考响应时间。在图2中，不同到达率的稳定点是不同的，应为每一个到达率单独寻找参考点。对于每一个$\lambda$来说，违反SLA的最大容器数量$n^r$被称为下限，它能够避免释放太多容器。对于每一个$\lambda$来说，不同数量的容器的稳定点可以从历史数据中学习。$W^T$和$n^r$可以从每一个$\lambda$的稳定点上得到。稳定点结合，$W^T$和$n^r$被称为$\lambda$的一个参考模型，其用于直到反馈控制。

![image-20211126103740591](image/Inverse%20Queuing_FIG_2.png)

<center>图2  在不同容器数量下，不同到达速录的平均响应次数</center>

&emsp;&emsp;我们提出了 一个自动参考模型学习算法(ARML)，基于$s=(n_s,\lambda_s,y_s)$形式的样本对参考模型进行剖析，其中$n_s$是容器数量，$\lambda_s$是到达率，$y_s$是平均响应时间。$M$是参考模型的集合。为了减少所研究的参考模型的数量，任何两个模型的参考到达率之间的差异应大于差距$g(e.g,5/s)$。既有相似到达率的样本应用来描述同一模型。  

&emsp;&emsp;ARML的形式描述见算法1。在弹性伸缩步骤$k$中，一个新的样本s将被收集，并试图找到一个相应的参考模型$m_k = \arg min_{m\in M} \{ \lambda_d=|\lambda_m-\lambda|,\lambda_d<g\}$。如果$m_k = null$，一个参考到达率为$\lambda$ 新的模型$m_k$会被创建并添加到集合$M$中。如果$m_k = m_{k-1}$，这意味着在两个连续的步骤之间，系统的到达率是稳定的，$s$将被按照如下方式处理。如果$y_s>W_{sla}$  and  $n_s > n^r_{m_k}$，$n_s$是一个很大的数量，这违反了SLA，并且$n^r_{m_k}$将被$n_s$替代。例如，$n^r_{m_k}=10$意味着提供10个容器会导致违反SLA，但是分配11个容器能够保证SLA。当$n_s=13$and$ y_s>W_{sla}$时获得一个新的样本,这意味着，分配13个容器不能够履行SLA。因此，13是一个新的不履行SLA的最大数量。当$y_s\leq W_{sla}$，$s$被存储在一个哈希码$h_{m_k} = <n,bt_n>$中，容器编号$n$是键，桶$bt_n$包含容器编号为$n$的样本的平均响应时间。对于每个$n$，只有最近的10个平均响应时间被存储在$bt_n$中，并且与平均值$average(bt_n)$相差大于$0.4 \times average(bt_n)$的值。然后根据每个$n$的过滤值更新$average(bt_n)$，并添加到集合$Y$中，最后，集合$Y$中第三大的值作为参考响应时间$W^r_{m_k}$。例如在图2中，当$W_{sla]}=0.1s$时，空心圆时第三大平均响应时间。不选择前两个最大的稳定点的原因是小的工作量波动可能导致违反SLA，因为前两个最大的稳定点在$W_{sla}$附近。如果$n_s \leq n^r_{m_k}$，这意味着一个，与$n^r_{m_k}$相比一个更小的或相等数量的容器能够履行SLA，$n^r_{m_k}$被更新为$n_s-1$。每当从系统中收集到一个新的样本$s$，$W^r_{m_k}$和$n^r_{m_k}$都会按照如上所述更新。只有当$n^r_{m_k}$被分配了一个值，并且hashmap中键$(h^{keys}_{m_k})$的数量大于4，模型$m_k$才是成熟的，并添加到一个成熟的模型集$M'$中。因为不成熟的模型没有足够的样本来提供适当的参考点和下限，所以它们不能被使用。

&emsp;&emsp;在$s$被添加到$m_k$中后，我们尝试找到一个成熟的参考模型$m'_k = \arg min_{m\in M'}\{\lambda_d = |\lambda_m-\lambda|,\lambda_d < g'\}$。$g'$通常被设置的比$g$大$(e.g.,20/s)$，以使成熟模型能够指导更多具有较大到达率差异的情况。只有当 $m_k$是成熟的时候，$m'_k = m_k$。如果找到$m'_k$，$W^T_{m'_k}$被选为参考响应时间，它将被作为反馈控制的参考点。否则，一个样本方法被激活来为$m_k$收集更多的样本。让$n^s_{m_k}$和$n'_{m_k}$作为$h_{m_k}$的最小和最大的键。如果$n^s_{m_k}-1>n^r_{m_k}$ or $n^r_{m_k} = null$，当前步骤$k$的容器数量$N_k$被设置为$n^s_{m_k}-1$。否则，$N_k = n'_{m_k}+1$。

![Inverse Queuing_Algorithm1](image\Inverse Queuing_Algorithm1.png)

### 4.3 基于逆排队模型的控制器设计

&emsp;&emsp;如果可以找到一个成熟的参考性能$m'$，反馈控制器被用于遵循参考时间$W^r_{m'_k}$。控制误差是
$$
e_k = W^r_{m'_k} - y_k
$$
&emsp;&emsp;运用公式(5)的性能模型和$e_k$来设计一个控制器。但是，直接使用混合非线性性能模型设计一个反馈控制器是非常复杂的。因此，排队模型的反函数被用来线性化性能模型，这简化了反馈控制器的设计，正如图3所示。因为从方程（4）直接推导出反排队函数是很复杂的。如算法2所示，使用穷举搜索法来实现反排队功能，在给定的平均响应时间$u_k$(控制输入)下找到相应的容器数量$N_k$。根据排队理念，总处理速率$N_k\times \mu$应该大于到达率$\lambda$以使得系统稳定。因此，$N_K$首先被初始化为$[\frac{\lambda}{\mu}]$。然后$N_k$基于$[\frac{\lambda}{\mu}]$一步步增加直到$W_s(N_k,\lambda,\,u)>u_k$。从$N_k$到$u'_k$的排队函数(排队模型部分)的性能模型被从$u_k$到$N_k$的反派对模型所抵消。 换句话说，如果排队模型部分在描述多容器系统时是准确的，那么$u_k' = u_k$。那么线性性能模型是：
$$
y_k = a \times y_{k-1} + (+-a)u'_{k-1} = a \times y_{k-1} + (1-a)u_{k-1}
$$
并且性能模型的Z转移函数是：
$$
\frac{Y}{U} = \frac{1-a}{z-a}
$$
基于线性部分设计了一个积分反馈控制器，但忽略了排队模型部分，具体如下 :
$$
u_k = u_{k-1}+K_1 \times e_k
$$
积分控制器的Z转移函数是：
$$
\frac{U}{E} = \frac{K_1z}{z-1}
$$
整个反馈系统的Z转移函数是：
$$
F_R(z) = \frac{Y}{R} =\\
\frac{\frac{1-a}{z-a}\frac{K_1z}{z-1}}{1+\frac{1-a}{z-a}\frac{K_1z}{z-1}}=\frac{(1-a)K_1z}{z^2+[(1-a)K_1-1-a]z+a}
$$
通过线性化，排队理论和反馈控制结合起来提供准确的性能建模和反馈能力。

![Inverse Queuing_FIG_3](image\Inverse Queuing_FIG_3.png)

<center>图3  基于容器化Web系统的混合控制器设计</center>

![Inverse Queuing_Algorithm2](image\Inverse Queuing_Algorithm2.png)

### 4.4 自适应输出误差映射方法

&emsp;&emsp;为了保证系统的稳定，控制输入$u_k$应该小于$W^u_s = W_s(n^r_{m'_k},\lambda,\mu)$来使得$N_k$大于$n^r_{m'_k}$。同时，为了分配不多于最大数量的可分配容器$N_m$，$u_k$应该小于$W^d_s = W_s(N_m,\lambda,\mu)$。因为$n^r_{m'_k}$是由一个样本确定的，可能会不准确。为了允许在$n^r_{m'_k}$上取样，$W^u_s$再次被设置为：
$$
W^u_s = \frac{W_s(n^r_{m'_k},\lambda,\mu)+W_s(n^r_{m'_k}-1,\lambda,\mu)}{2}
$$
&emsp;&emsp;输出误差通过公式(9)来调整$u_k$。但是，参考模型$m’_k$和分析性能模型之间仍有不可避免地偏差，正如图4所示。当偏差过大时，$u_k$可能会发生很大变化，并超过排队模型部分的下限或上限$[W_s^d,W^u_s]$。设$[W_s^d,W^u_s]$为参考模型的下限和上限，分别为小于$W_{sla}$的最小和最大响应时间。为了保证边界$[W_s^d,W^u_s]$，提出了一个自适应输出误差映射方法(AOM)，将$e_k$从参考模型空间映射到排队模型空间地输出误差$e'_k$上。

#### 定理 1 

如果参考模型的输出误差按比例映射到性能模型中。他们
$$
e'_k = e_k \times K_n
$$

$$
K_a = \begin{cases}
\frac{u_{k-1}-W^d_s}{y_k-W^d_{m'_k}},y_k>W^r_{m'_k} \\
\frac{W^u_s-u_k-1}{W^u_{m'_k}-y_k},Otherwise\\
\end{cases}
$$

#### 证明

&emsp;&emsp;假设目标参考点$u^r(unknwn)$在排队模型空间中，它能够使系统得到响应时间$W^r_{m'_k}$。那么$e'_k = u^r - u_{k-1}$。映射地主要意图是找到一个合适的$e'_k$使得$u_k$越来越接近$u^r$。根据公式(5)，$a \times y_{k-1}+(1-a)u^r$，$a \times y_{k-1}+(1-a)W^d_s$和$a \times y_{k-1}+(1-a)u_{k-1}$分别是排队模型空间中$u^r,W^d_s,u_{k-1}$地完整性能模型(排队模型和线性部分地总和)对应的值。性能模型的输出误差是$e^p_k = (a \times y_{k-1}+(1-a)u^r)-(a \times y_{k-1} + (1-a)u_{k-1})$。如果参考模型的值按比例映射到性能那个模型中，$e_k$与$y_k-W^d_{m'_k}$的比率等同于$e^p_k$与$(a \times y_{k-1}+(1-a)u_{k-1})-(a \times y_{k-1}+(1-a)W^d_s)$的比率，如下所示:
$$
\frac{e_k}{y_k-W^d_{m'_k}}\\
=\frac{e^p_k}{(a \times y_{k-1}+(1-a)u_{k-1})-(a \times y_{k-1}+(1-a)W^d_s)}\\
=\frac{(1-a)(u^r-u_{k-1})}{(1-a)(u_{k-1}-W^d_s)}=\frac{e'_k}{u_{k-1}-W^d_s}
$$
&emsp;&emsp;当$y_k \leq W^r_{m'_k}$时，证明是类似的。

&emsp;&emsp;为了避免大的波动，当$K_a>1$时，$K_a$被修改为1。通过把公式(9)中的$e_k$提华为$e'_k$，积分控制器成为
$$
u_k = u_{k-1}+K'_I \times e_k
$$
其中$K'_I = K_I \times K_A$被称为自适应控制增益。

![Inverse Queuing_FIG_4](C:\Users\12396\Desktop\文章\NJUST_paper\image\Inverse Queuing_FIG_4.png)

<center>图4 从参考模型映射到分析队列模型</center>

### 4.5 基于排队长度的不稳定状态调度

&emsp; &emsp;当到达率大$\lambda$于总处理能力$\mu$时,系统是不稳定的，并且公式(2)(3)(4)是不成立的。因此，直接根据$e_k$找$N_k$是不合适的。在不稳定的状态下，实际队列长度$L$大于$L_s(N_k,\lambda,\mu)$，并且不断增加，直到到达允许的最大等待连接数，这代表了阻断程度。因此，采用基于排队长度的不稳定状态供应方法 ，正如算法3所示。首先，如果$n_s > n^r_{m_k}$，这意味着$n_s$是不符合SLA的较大容器数量，用$n_s$替换 $n^r_{m_k}$。给定$N_k$个容器，根据公式(5)，下一步的理论响应时间$y_{k+1}$是当前响应时间$y_k$和排队模型的期望响应时间$W_s(N_k,\lambda,\mu)$的加权。使用迭代搜查来寻找基于$[\frac{\lambda}{\mu}]$使$y_{k+1}>W_{sla}$的容器的最小数量$N_k$。每一步都应该至少增加一个新的容器。每一秒钟，在此步新添加的$N_k - N_{k-1}$个容器可以处理附加的$\mu \times (N_k - N_{k-1})$个请求。为了确保通过在$N_k - N_{k-1}$个容器上处理$\mu \times(N_k - N_{k-1}) \times T_r$个附加请求，实际队列长队$L_r$能够在$T_r$秒减少到理论排队长度$L_s$，$N_k$逐步减少。较大的$T_r$会更快减少排队长度。最终，$u_k$被更新，以保证在下一个控制步骤中，如果没有输出误差，$N_k$个容器人能够被租用。

![Inverse Queuing_Algorithm3](C:\Users\12396\Desktop\文章\NJUST_paper\image\Inverse Queuing_Algorithm3.png)

### 4.6 基于逆排队模型的反馈控制正式描述

&emsp;&emsp;在算法4中正式描述了基于逆排队模型的反馈控制。首先，使用历史数据对性能模型进行分析。在排队系统中，当实际排队长队$L_r$大于理论排队长度$L_s(N_k,\lambda,\mu)$，系统是不稳定的。给定到达率$\lambda$，为使系统稳定，至少需要$N = [\frac{\lambda}{\mu}]$个容器。$N$个容器的理论响应时间是$W_s(N,\lambda,\mu)$，这叫做最大稳定响应时间。当$y_k$大于最大稳定响应时间时，系统也是不稳定的。因为在排队模型和实际系统之间仍是由偏差的，即使系统是稳定的，排队长度也可能偶尔比理论上的排队长度大一点儿。上述不稳定的标准过于严格，容易导致稳定和不稳定控制之间的频繁切换，使得系统波动很大。因此，只有当$L_r$大于$L_s(N_k,\lambda,\mu)$的$α$倍或$L_r$大于$W_(N,\lambda,\mu)$的$β$倍时，系统才被认定为不稳定的。给出更大的$α$和$β$意味着判断系统不稳定的标准更加宽松。如果系统是不稳定的，QLP就会被调用。否则，调用ARML来霍格一个参考模型$m'_k$或者获得一个样本$N_k$。如果$m'_k \neq null$，使用公式(16)来获取$u_k$，并且使用逆排队模型来获取实际控制动作$N_k$。最终，分配个Web系统的容器数量被调整为$N_k$。

![Inverse Queuing_Algorithm4](C:\Users\12396\Desktop\文章\NJUST_paper\image\Inverse Queuing_Algorithm4.png)

## 5 性能评估

&emsp;&emsp;我们提出的基于逆排队模型的反馈控制作为Kubernetes的一个用户及调度来实现。与现有算法在真实的Kubernetes集群上比较，它位于四台物理机上，配置为 6~12个虚拟CPU核心和 8~16GB内存。Kubernetes集群包括一个Master节点和4个Worker节点。一个计算斐波那契数的服务被作为测试平台，该服务的输入是生成的斐波那契数列的长度，它从每个请求的区间中随机选择。$W_{sla}$时0.1秒。nginx-ingress-controller使用指数加权移动平均(EWMA)作为负载平衡算法，将服务请求重定向到不同的容器。每个请求的响应时间都存储在nginx的日志中。ASC通过Kubernetes的java客户端接口(JCI)读取日志，获得每分钟的平均响应时间。 排队长度和请求到达率是通过使用http protocal读取nginx的状态信息获得的。由ASC生成的Pod弹性伸缩命令通过JCI改变部署的副本的值，发送到Kubernetes。nginx的连接超时时间是10秒，并且每个容器允许的最大连接数是500。维基百科的用户访问痕迹，如图5所示，与Web系统的常见峰值和谷值 是通过JMeter来生成请求。

![Inverse Queuing_FIG_5](C:\Users\12396\Desktop\文章\NJUST_paper\image\Inverse Queuing_FIG_5.png)

<center>图5 维吉保科访问痕迹的请求到达率</center>

&emsp;&emsp;首先，FeedBack_InverseQM与FeedBack_QMDL进行了比较，后者是一种经典的反馈控制方法，用于基于排队模型衍生的线性模型的QoS控制。尽管Feedback_QMCA是为按小时计价的虚拟机供应而定制的，但FeedBack_InverseQM仍然通过移除虚拟机释放状态检查与Feedback_QMCA进行比较。最后，Feedback_InverseQM也与Feedback_InverseP进行了比较，后者是考虑到QoS控制的弹性容器供应算法之一。平均响应时间和总消耗的CU是算法比较的衡量标准。所有算法的控制区间长度为250秒。由于FeedBack_InverseQM有一个初始采样期，为了公平比较，每个被比较的算法的成本只是初始500分钟后消耗的CU的累积。

#### 5.1 参数处理

&emsp;&emsp;控制增益$K_I$决定了系统的极点，这对沉降时间和过冲有很大影响。可以通过设置以下方式得出极点，给定$K_I$ ，z^2 + [(1-a)K_I - 1-a]z+a = 0。例如，当$K_I = 0.6$时，极点$p_1 = 0.44+0.32619013j$，极点$p_2 = 0.44-0.32619013j$。根据根基位置，随着$K_I$的变化画出极点图，较大的$K_I$通常意味着较大的超调，过小或过大的KI都可能产生较长的沉降时间。根据根基选出一组候选值的集合$S_{ki} = {0.05,0.1,0.15,0.3,1.6}$ 。然后通过实验来评估$K_I \in S_{ki}$的实际性能。图6和图7显示了不同$K_I$下FeedBack_InverseQM的消耗的容器数量和平均响应时间，说明FeedBack_InverseQM的容器数量随着$k_i$总量的增加而变化得更快。对于较小的$K_I$，FeedBack_InverseQM对过剩的容器和违反SLA的反应非常缓慢。例如，当$K_I = 0.05$时，过剩的容器不能及时地释放，消耗了最多的成本(2454 CUs)，并且当$K_I = 0.1$时，SLA被多次违反。相反，对较大地$K_I$来说，当$K_I = \geq 0.3$时，容器数量地剧烈波动导致更多地违反SLA地行为，并且极大的$K_I = 0.6$时，因频繁地容器分配和取消分配，甚至产生了第二大成本(2290 CUs)。因此，$K_I = 0.15$是最终选择，它可以获得最合适的控制强度，同时导致更少的违反SLA和更低的成本。

![Inverse Queuing_FIG_6](image\Inverse Queuing_FIG_6.png)

<center>图6 不同Ki下FeedBack_InverseQM的容器数量</center>

![Inverse Queuing_FIG_7](image\Inverse Queuing_FIG_7.png)

<center>图7 不同Ki下FeedBack_InverseQM的响应时间</center>

根据[30]的性能评估结果，Feedback_QMDL和Feedback_QMCA的极值分别被设定为0.9和0。Feedback_InverseP的极点被设定为0.95，与[19]一致。

&emsp;&emsp;为了获取性能模型的评估值，采用最小平方方法，基于从Kubernetes平台，在$0<a<0.3,\mu_b>0，c>0$的约束下收集的历史数据（包括平均响应时间、容器数量和到达率）。如果没有$0<a<0.3$的约束，很有可能得到$a>0.9$，因为两个连续的响应时间之间的相似性，这将抑制排队模型部分的影响。约束条件$c>0$是用来保证处理能力随着到达率的增加而降低的。如果训练模型的$\mu_b$小于0，当$\lambda >\frac{c}{-\mu_b}$时，处理能力$\mu$将会小于0，这意味着模型是无意义的。因此，$\mu_b>0$是必须的。在我们基于Kubernetes的平台中，根据历史数据得到$\mu_b = 7.771,c = 1574.510,a = 0.215$，它们可能会随着时间的推移而改变。基于固定处理率的性能模型的参数可以通过设置$c = 0$类似的获得。图8展示了实际响应时间和剖析性能模型的估计值，说明所提出的基于变化处理率的方法（蓝点）比基于固定请求处理率的方法（绿点）更准确地描述系统。

![Inverse Queuing_FIG_8](image\Inverse Queuing_FIG_8.png)

<center>图8 分别使用固定处理率和变化处理率的实际响应时间和剖析性能模型的估计值</center>

#### 5.2 实验结果

&emsp;&emsp;表三展示了违反SLA的百分比和比较算法的小号，这说明提出的FeedBack_InverseQM获得最低违反SLA八分比(比现有算法低8.44个百分点)并获得第二最低总消耗(2250 CUs)。

![Inverse Queuing_Table3](image\Inverse Queuing_Table3.png)

&emsp;&emsp;图9展示了FeedBack_InverseQm的容器数量和响应时间 ，这表明大多数响应时间都小于$W_{sla}$。FeedBack_InverseQM的最佳表现的原因如下。首先，FeedBack_InverseQM的ARML有助于提高输出误差的准确性。因为不同的到达率有不同的稳定点，所以通过ARML收集样本来研究不同到达率的参考响应时间，导致图9的初始阶段出现一些波动。图2显示了两个不同到达率的成熟参考模型的稳定点。在图10中，研究的参考时间随时间变化，这增加了输出误差的准确性。第二点，FeedBack_InverseQM的AOM能够提高控制的稳定性。如图4所示，当$u_{k-1}$在排队模型的相对扁平部分附近时，FeedBack_InverseQM对输出误差很敏感。性能模型的扁平化部分反映了排队系统的性质，使控制器能够对违反SLA的行为做出快速反应。但是，参考模型和分析的排队模型之间存在不可避免的偏差。有时，基于参考模型的原始输出误差是很大的，这使得$u_k$出现了剧烈的波动。图11显示了由AOM产生的不同步骤的自适应控制增益，这些增益被用来将输出误差从参考模型按比例映射到排队模型，以避免这种激烈的波动。如图9所示，除了初始采样阶段，ARML和AOM都使FeedBack_InverseQM获得最稳定的性能。

![Inverse Queuing_FIG_9](image\Inverse Queuing_FIG_9.png)

<center>图9 FeedBack_InverseQM的容器数量和响应时间</center>

![Inverse Queuing_FIG_10](image\Inverse Queuing_FIG_10.png)

<center>图10 成熟模型的控制步骤的参考响应时间</center>

![Inverse Queuing_FIG_11](image\Inverse Queuing_FIG_11.png)

<center>图11 不同控制步骤的自适应控制增益</center>

&emsp;&emsp;图12表明，FeedBack-QMDL对快速到达率的变化反应缓慢，导致违反SLA或延迟释放多余的容器。其原因是 FeedBack-QMDL的输出是M/M/N模型的输出和反馈控制决定的附加值的总和。同时，不同的到达率需要相当不同的附加值，而且当到达率快速变化时，附加值的变化速度不能满足要求。然而，附加值的变化速度不能再通过设置较小的极值（如0.6）来增加，因为对于到达率变化速度较慢的场景，它可能会分配或释放多余的容器，产生更多的违反SLA或更高的成本。主要原因是附加值的变化速度是固定的，与输出误差呈线性关系，没有考虑不同变化速度的各种到达率。

![Inverse Queuing_FIG_12](image\Inverse Queuing_FIG_12.png)

<center>FeedBack_QMDL的容器数量和响应时间。</center>

&emsp;&emsp;图13表明，FeedBack_QMCA很可能分配或取消多余的容器，导致在到达率变化速度较慢的时期经常出现大的波动，其原因如下。在FeedBack_QMCA中，排队模型的不精确性被一个到达率调整系数所固定。实验结果表明，不同的到达率需要相当不同的调整系数。当到达率快速变化时，需要很长的时间来调整系数，导致违反SLA或在控制收益较小的情况下产生较高的成本。因此，为了加快调整系数的变化速度，满足快速到达率变化的要求，当前的比例控制增益被尽可能地提高。然而，满足快速变化的到达率的控制器增益，在到达率缓慢变化时，会使系统发生波动。很难找到一个适合不同到达率变化速度的适当增益。同时，一个固定的参考点不能为所有的到达率产生合适的输出误差，从而误导控制器释放或租用多余的容器，导致违反SLA或增加成本。

![Inverse Queuing_FIG_13](image\Inverse Queuing_FIG_13.png)

<center>图13 FeedBack_QMCA的容器数量和响应时间</center>

&emsp;&emsp;图14显示，FeedBack_InverseP的容器数波动剧烈，虽然给出了0.95的大极点（沉降时间长），但还是经常违反SLA。FeedBack-QMDL和FeedBack_QMCA都使用改变后的附加值或到达率系数来修正排队模型的不准确性，从而避免了容器数量的剧烈波动。相反，与FeedBack_InverseQM类似，FeedBack_InverseP的反比例性能模型在$u_{k-1}$接近性能模型的相对平坦部分时，也对输出误差非常敏感。然而，一个固定的参考点和反比例性能模型与真实系统之间的不一致，不能总是为不同的到达率招致容器数量的激烈波动而产生适当的输出误差。

## 6 总结和未来工作

&emsp;&emsp;本文提出了一种基于反排队模型的反馈控制方法，以便在基于Kubernetes的平台上为Web系统弹性地提供容器，保证QoS。实验结果表明，基于变化处理率的排队模型和线性模型的混合能够提高性能模型的准确性。同时，自动参考模型学习和自适应输出误差映射提高了输出误差的准确性，使违反SLA的百分比降低了8.44%，并获得了第二低的成本。考虑到云、雾和边缘资源的地理分布，设计容器自动扩展算法是有前途的未来工作。

