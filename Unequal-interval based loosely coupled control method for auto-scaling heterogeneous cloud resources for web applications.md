## Unequal-interval based loosely coupled control method for auto-scaling heterogeneous cloud resources for web applications

## （基于不等间隔的松散耦合控制方法用于网络应用的弹性伸缩异构云资源）

### 概要

&emsp;&emsp;大多数现有的网络应用程序的服务质量（QoS）控制算法考虑到了网络服务器或数据库连接，这些连接可以立即释放。 然而，许多应用程序被部署在虚拟机（VM）上，甚至是从公共云中弹性租用的Spot虚拟机。为了节约成本，在租用的间隔期结束之前，间隔期收费的虚拟机不会被释放。这种控制效果的延迟，使现有的方法租用或释放多余的虚拟机会导致过度控制。波动的价格使spot虚拟机因意外终止而变得不可靠，这使得容错策略至关重要。本文提出了一种基于不等间隔的松散耦合控制方法，以提高容错策略的服务质量（QoS）控制能力。一个带有到达率调整系数的排队模型被用来预测所需容量，作为一个前馈控制器。另一种基于双阈值和排队模型的方法被用来更新系数，作为松散耦合的反馈控制器。同时，提出了不等间隔控制器协作方法，以避免过度控制并对工作量的变化做出快速反应。我们的方法在一个模拟平台和一个真实的$Kubernetes$集群上进行了评估。实验结果表明，与现有的算法相比，我们的方法减少了大于服务水平协议的等待时间的百分比，而租赁成本却类似或更低。

### 关键词

云计算，反馈控制，排队模型，资源配置，spot虚拟机 

### 1 介绍

&emsp;&emsp;云计算提供了面向订阅的服务，它广泛地以弹性方式租用云虚拟机（VM）来支持网络应用的运行。虚拟机一般按时间间隔定价，基于小时的定价模式在现代商业公有云中特别流行。亚马逊EC2、微软Azure、阿里云等的On-demand虚拟机的价格是固定的。相反，亚马逊EC2的现货虚拟机的价格是动态的，因为spot虚拟机是由公共云拍卖的。即期虚拟机比On-demand虚拟机便宜，但由于在当前市场价格高于出价时要终止租赁，所以不可靠。 大多数现有的网络应用的QoS控制方法只关注一个服务器内的资源或On-demand虚拟机。然而，租用Spot虚拟机来降低虚拟机的租赁成本是很有好处的。本文的主要目标是弹性配置Spot和On-demand虚拟机，在保证请求的平均等待时间和稳健性的同时，最大限度地降低资源租赁成本。提供现货虚拟机的主要挑战是基于间隔的定价模型，非线性的系统性能和现货虚拟机的不可靠。

&emsp;&emsp;基于间隔的定价模式使资源供应变得复杂。大多数网络应用程序的反馈和前馈控制方法主要集中在服务器、网络服务器会话或数据库连接的进程分配上，这些进程可以被快速释放。然而，云虚拟机通常是按小时计价的，云用户需要为整个租用的小时付费，即使只使用了前几分钟。因此，在做出释放决定后，立即释放租用的虚拟机，是一种成本浪费。虚拟机确实是在租借时间结束后才被释放的，这推迟了控制效果的出现。这种延迟可能会导致控制人员释放更多的虚拟机，从而导致过度控制。同时，在现有的控制方法中，反馈控制器只用于修正前馈控制器的输出，这意味着反馈和前馈控制器每次都要一起调用。 然而，虚拟机的间隔定价模型限制了调用反馈控制器的频率，这使得该算法对环境变化的反应缓慢。因此，挑战之一是设计适当的反馈和前馈协作方法，考虑独特的基于区间的定价模型。

&emsp;&emsp;非线性的系统性能和Spot VM的不可靠性使Spot虚拟机的租赁也变得复杂。系统性能和虚拟机资源量之间的关系是非线性的。大多数现有的反馈控制方法都是基于线性、反比例模型或M/M/1模型衍生的线性模型，它们在稳定状态下表现良好，但在面对巨大的工作负荷变化时表现不佳。同时，现有的保证QoS的控制方法通常侧重于稳定的资源，而不是不可靠的spot虚拟机。QoS控制不是现有的Spot虚拟机高效容错策略的主要重点。因此，另一个挑战是如何设计结合适当的QoS反馈控制和容错方法的算法。

&emsp;&emsp;本文提出了一种基于不等间隔的松散耦合控制方法（UCM），该方法同时考虑了容错和QoS保证。在UCM中，带有到达率调整系数的M/M/N排队模型被应用于预测基于当前工作量的所需资源容量，作为一个前馈控制器。为了修正M/M/N排队模型的不准确性，另一个基于M/M/1模型的反馈控制器被用来更新系数而不是前馈控制的输出，以使输出误差最小化。同时，基于松散耦合的前馈和反馈结构，提出了一种不等间隔的前馈和反馈协作方法，通过虚拟机释放状态检查和差异化的反馈和前馈调用频率，避免了过度控制并对工作负荷的变化做出快速反应。 最后，一个基于双阈值的输出误差计算方法被用来减少粗粒度的虚拟机容量所产生的波动。以下是本文的主要贡献:

1.提出了一种新的松散耦合的控制方法，它使用反馈控制器，通过调整排队模型的参数而不是排队模型的输出，来修正基于排队模型的前馈控制器。

2.考虑到控制效果的延迟和对工作量变化的快速反应，开发了一种不等间隔的协作方法来选择合适的反馈和前馈调用频率。

3.基于M/M/1排队模型，建立了调整比例与预期等待时间变化的函数，以提高反馈控制的准确性，并采用了基于双阈值的控制误差计算方法来减少控制的不稳定性。

&emsp;&emsp;以下是本文其余部分的结构。第二部分包括对相关工作的简要回顾。第3节描述了现有的基于组的容错（$GFT$）的Spot虚拟机租用方法，然后在第4节进行问题描述。第5节介绍了拟议的松散耦合控制方法。第6节介绍了评估结果，第7节是关于结论和未来工作。

### 2 相关工作

&emsp;&emsp;保证网络应用的QoS的方法可以分为两类:主动和被动的方法。 例如，排队理论和基于强化学习的前馈控制是主动的方法。线性或非线性性能模型和基于阈值的反馈控制是被动的方法。事实证明，使用基于阈值的反馈控制和基于强化学习的前馈控制都是很棘手的，甚至不小心就会失败。例如，基于阈值的反馈控制总是需要用户根据具体应用的信息来手动设置规则。强化学习通常需要很长的初始化和学习期，这需要仔细设计收敛加速技术。基于排队模型的前馈控制是一种有效和高效的方法，可以预测具有动态到达率的情景下所需的资源容量。Jiang等人提出了一种基于M/M/N排队模型的前馈虚拟机供应方法，以保证QoS并同时最小化租赁成本。Wang等人开发了一个基于不平等服务器的排队模型，将数据中心的资源分配给不同的应用。然而，在排队模型和真实环境之间存在不可避免的偏差。基于前馈的方法缺乏对实时性能的反应能力。

&emsp;&emsp;基于线性或反比例性能模型的反馈控制方法已被广泛用于传统的计算系统中，以根据实时性能调整提供的资源。然而，当反馈控制被应用于云计算应用时，存在许多挑战。大多数现有的反馈控制方法都是基于细粒度的资源，如网络服务器进程或数据库连接，而不是具有固定容量的粗粒度的虚拟机，而且这些细粒度的资源可以快速分配和释放，这与间隔充电的云虚拟机有很大不同。Lu等人和Patikirikorala等人应用基于线性模型或多线性模型切换的反馈控制，将网络服务器的进程或会话分配给不同类别的请求 以提供差异化的服务。Pan等人和Karlsson等人开发了基于线性模型的反馈控制方法，用固定或在线估计的增益参数来分配有限的数据库连接。Padala等人应用在线参数估计技术来提高基于线性模型的反馈控制的鲁棒性，以便将物理机器的CPU和磁盘分配给不同的应用。然而，线性或反比例性能模型不能准确描述系统，这使得反馈控制对环境变化的反应不准确，因为计算系统通常具有复杂的非线性性能特征。同时，由于基于间隔的云计算虚拟机定价模型导致了控制效果的延迟，现有的反馈控制方法可能会出租或释放多余的虚拟机。也有一些现有的算法是为弹性配置虚拟机而设计的。Lim等人提出了一种基于线性模型的反馈控制方法，通过调整虚拟机的数量来控制CPU的利用率。 Al-Shishtawy和Vlassov应用了一种基于线性模型的反馈控制方法，使用吞吐量和虚拟机数量的比率作为在线商店系统的控制输入。为了更准确地描述系统，Baresi等人开发了一个基于反比例-性能模型的比例-积分（PI）控制器，以将容器分配给云应用。然而，这些方法没有考虑到Spot虚拟机或虚拟机的释放延迟。

&emsp;&emsp;为了保证网络应用的QoS，有一种趋势是使用反馈控制来补偿排队模型或其他主动方法的不精确性。排队模型和反馈控制的结合是一种有效和快速的方法，使系统遵循参考的平均等待时间。然而，在现有的用于网络应用服务质量控制的反馈和前馈混合控制算法中，反馈控制器通常只用于修正前馈控制器的输出（称为平行连接），这不适用于间隔充电的云虚拟机。ha等人应用一个基于一阶线性模型的PI控制器来修正排队模型。同样地，Lu等人使用基于线性模型的反馈控制来调整基于排队模型的前馈控制器的输出。Xu等人开发了一种混合控制方法，该方法也使用比例积分导数控制器来纠正排队模型的不精确性。基于区间的定价模型限制了调用反馈控制器的频率，以避免过度控制。例如，反馈控制器不能在最多1小时内被调用，等待虚拟机在租用时间结束后真正释放。 然而，传统的并行连接的结构限制了反馈和前馈控制器必须一起调用，这延迟了对工作量变化的反应。

&emsp;&emsp;目前已经有一些针对云网络应用的容错调度方法。Qu等人研究了一种用于网络应用的$GFT$ Spot虚拟机租用方法，该方法租用了多组不同类型的Spot VM以提高系统的稳健性。 然后，Liu等人通过应用价格预测和设置最小虚拟租借期限来扩展基于小组的方法，以进一步降低租赁成本。这两种方法主要侧重于容错策略，没有考虑到QoS控制。将容错策略和间隔定价模型感知的QoS控制方法结合起来，有益于提高鲁棒性、降低租赁成本和保证QoS。

&emsp;&emsp;我们的方法UCM和现有算法的比较见表1。UCM由间隔定价模型感知的QoS控制和容错方法两部分组成。在UCM中，反馈和前馈控制器是松散耦合的，而不是平行连接的。反馈控制器被用来更新基于M/M/N的前馈控制器的参数。松散的耦合结构使其有可能分别调用具有不等时间间隔的反馈和前馈控制器。例如，前馈控制器可以单独调用，而且比反馈控制器更频繁，以便对工作量的变化作出快速反应。同时，反馈控制器应用基于M/M/1的到达率系数调整模型来提高反馈控制的准确性。

![Unequal-interval_Table1](image\Unequal-interval_Table1.png)

### 3 背景-现有的GFT虚拟机租赁方法

&emsp;&emsp;Liu等人通过增加spot价格预测和设置最小租赁时间限制来扩展现有的$GFT$现货VM租赁方法，以进一步降低租赁成本。主要思路如下，扩展的$GFT$的细节可以在参考文献中找到。同时租用多组Spot VM，以提高稳健性。 每组具有相同的容量，由相同类型的虚拟机组成。对于以百万条指令为单位的所需资源容量$R$。首先租用容量为$R_0 = C_0 \times N_0$的On-demand虚拟机，其中$C_0$是每个On-demand虚拟机的容量，$N_0$是租用的On-demand虚拟机数量。 然后，$N_s$组spot虚拟机被租用，每组的子容量为$Q = (R-R_0)/N_s$。为了提高容错能力，租用了$f$组额外的Spot虚拟机，每组也有$Q$的容量，$f$被称为容错水平。因此，租用的spot虚拟机的总容量为$[(R-R_0)/N_s]\times (N_s+f)$。

&emsp;&emsp;对于给定的$R$和$f$，选择适当的$N_0、N_s$和不同组别的Spot虚拟机类型对最终的租金成本有很大影响。这些数值的不同组合导致了不同的计划。扩展$GFT$的形式描述见算法1。 让$R_c$和$N_e$是用于生成当前计划的最后所需的虚拟机容量和现有组的数量。当所需容量$R>R_c$时，需要更多的资源。当当前计划的持续时间$T_P$短于阈值$T_u$时，只有每组的容量是根据新的$R$。否则，就会选择一个更便宜的计划，如下所示。如果只有按需租用的虚拟机，让$N_{o\_max}$成为最大的虚拟机数量。对于每个候选$N_o \leq N_{o \_max}$，评估不同数量的Spot组$N_s$。$N_s$被设定为大于$N_e$，这意味着只考虑有更多组的Spot虚拟机的计划，以避免大的波动。$N_s$也应该小于$N_{sp}$（系统中所有可用的Spot VM类型的数量）和$N_{al}$（允许租用Spot VM类型的最大数量）。对于每个spot类型，首先通过时间序列分析方法预测未来$h$小时的价格。$N_{al}$通常被设定为比$N_{sp}$小，以增加通过预测选择稳定的现货类型的可能性，因为如果没有设置$N_{al}$限制，$GFT$总是倾向于租用所有可用的组以节省成本。首先根据预测的spot价格计算现有$N_e$组新产能$Q$的租金成本。然后，对于每个未租用的Spot类型，所需的虚拟机数量为$[Q/[MIPS \times (1-d_{margin})]]$，其中MIPS是虚拟机类型每秒执行的指令数，$d_{margin}$是突发工作负载的保证金资源的百分比。而且，每个未出租的现货类型的租赁成本也是根据预测的现货价格获得的。接下来，选择租金最便宜的$N_s-N_e$个未出租的Spot类型。所有$N_s$个小组的总成本是由现有的$N_e$个小组和选定的$N_s-N_e$个未租赁的Spot类型的租金成本相加得到的。这个过程反复进行，最后选择最便宜的计划。相反，当所需容量$R<R_c$时，计划保持不变，只使用新的容量$R$减少每组的容量。 当一个Spot虚拟机处于定价点（租用间隔的结束）时，只有当其所在组的剩余Spot虚拟机的容量仍不低于$Q$时，才会释放它。

![Unequal-interval_Algorithm_1](image\Unequal-interval_Algorithm_1.png)

### 4 问题描述

&emsp;&emsp;所考虑的网络应用程序由一个或多个层组成，如图形界面层、业务逻辑层和数据库层。从公共云中弹性地租用多种类型的云虚拟机，以建立一个虚拟的数据中心，支持每层的运行。每个层级都以多个容器的形式部署在不同类型和数量的租用虚拟机中。这些容器由$Kubernetes$组织，实现自动请求转发和生命周期管理。为了在保证平均等待时间的同时尽量减少虚拟机的租用成本，设计了一个资源调度器，根据每个层级的实时工作负荷动态地租用或释放虚拟机。网络应用程序的服务水平协议（$SLA$）通常规定了平均等待时间的分布，例如，$k$%的请求的等待时间应不超过$W_{sla}$的上限。虽然不同层的资源配置会相互影响，但为了简化，一般还是将应用的总体$W_{sla}$分解为各层的$W_{sla}$，并分别设计各层的弹性伸缩方法。本文为资源调度器设计了一种混合控制方法，考虑到虚拟机租赁成本和平均等待时间，分别调整每个单层的虚拟机容量。这种控制方法可以直接作为单层网络应用的资源弹性伸缩器，也可以作为多层应用的每个单层的资源弹性伸缩器。

### 5 提出的控制方法

&emsp;&emsp;本节提出了一种基于不等间隔的松散耦合前馈和反馈控制方法（UCM），以调整$GFT$的所需资源容量$R$，增加$GFT$的QoS控制能力。首先，描述了混合控制方法的结构，然后分别介绍了前馈和反馈控制器。然后，介绍了两个控制器的协作方法。最后，给出了 给出了UCM的正式描述。

#### 5.1 松散耦合控制方法的结构

&emsp;&emsp;图一展示了提出的松散耦合控制器的结构。M/M/N排队模型被应用于预测基于当前请求到达率和最大预期等待时间的资源需求。前馈控制器的输出是所需的资源容量$R$，它将被用于使用$GFT$更新网络应用层的虚拟机。为了修正M/M/N模型的不准确性，前馈排队模型的到达率通过乘以一个系数$\varphi$来调整，这个系数是由另一个基于排队模型的反馈控制器动态学习的。换句话说，反馈控制器负责学习基于排队模型的前馈控制器的参数。然后，根据学到的参数，前馈控制器可以被单独调用，并且比反馈控制器更频繁地调用。为了使平均等待时间小于$W_{sla}$，反馈控制器的参考等待时间$W_r$应该小于$W_{sla}$。为了与反馈控制器保持一致，前馈排队模型的最大预期等待时间也被设定为$W_r$。

![Unequal-interval_Fig_1](image\Unequal-interval_Fig_1.png)

<center>图1 松散耦合控制系统的结构</center>



#### 5.2 基于可调到达率的前馈控制器的排队模型

&emsp;&emsp;每个网络应用层通常由多个具有不同处理率的虚拟机组成。为具有异质虚拟机的集群建立一个关于平均等待时间、请求到达率和虚拟机容量的性能模型是非常复杂的。为简化起见，假设集群只由最低配置的相同虚拟机组成。而两个请求到达的时间间隔和请求处理时间具有负指数分布，参数为$\lambda$（到达率）和$\mu$（处理率）。然后，用相同的服务器的M/M/N模型来描述异构系统。在M/M/N中，每台服务器是一个配置最低的虚拟机，有$N$个相同的服务器。根据给定的到达率$\lambda$，每个服务器的处理率$\mu$和参考等待时间$W_r$，可以通过排队理论得到最小的$N$个数，如下所示。

&emsp;&emsp;对于M/M/N，队列中没有等待请求的概率为:
$$
P_0 = [\sum_{k = 0}^{N-1}\frac{1}{k!}\frac{\lambda}{\mu}+\frac{\lambda^N}{N!(1-\frac{\lambda}{N \times \mu})\mu^N}]^{-1}
$$
&emsp;&emsp;队列中的请求数的期望值为:
$$
L_q = \frac{(\frac{\lambda}{\mu})^N\frac{\lambda}{N \times \mu}}{N!(1-\frac{\lambda}{N \times \mu})^2}P_0
$$
&emsp;&emsp;等待时间的期望为：
$$
W_q = \frac{L_q}{\lambda}
$$
&emsp;&emsp;找到满足$W_q \leq W_r$的最小数量的$N$，以保证$W_r$。由于推导出$W_q$对$N$的原始函数的反函数是很复杂的，因此提出了一种穷举搜索法来寻找满足$W_r$的最小服务器数量，如算法2所示。为了修复排队模型的不准确性，测量的到达率$\lambda_m$乘以一个系数$\varphi(t)$，以产生一个调整的到达率$\lambda$，即$\lambda = \lambda_m \times \varphi(t)$。然后，因为处理率不能小于到达率，虚拟机的基本数量由$N = [\frac{\lambda}{\mu}]$产生，接下来，虚拟机的数量被逐一增加，直到排队模型的预期等待时间不大于$W_r$。最后，得到所需的容量$R = N \times C_l$，它将被用作$GFT$的输入。图2显示了前馈控制器的结构。

![Unequal-interval_Algorithm_2](image\Unequal-interval_Algorithm_2.png)

![Unequal-interval_Fig_2](image\Unequal-interval_Fig_2.png)

<center>图2 基于可调到达率的前馈控制器的排队模型</center>

#### 5.3 基于双阈值和排队模型的反阔控制器

&emsp;&emsp;由于排队模型的不准确性和系统工作量的变化，平均等待时间$y(t)$可能偏离参考等待时间$W_r$。系数\varphi(t)应被更新以应对$W_r$和$y(t)$之间的当前偏差。如果$y(t)>W_r$，则系统处于低供给状态，$\varphi(t)$应被放大以增加$R$。相反，系统处于超供给状态，$\varphi(t)$应被缩减以减少$R$。如果调整过多的$\varphi(t)$，系统可能会跳过正常状态，并在超供给和低供给状态之间动。因此，关键是要确定调整多少系数$\varphi(t)$才能使系统恢复到正常状态。在这篇文章中，$\varphi(t)$每次都由调整率$w$更新，即$\varphi(t) = \varphi(t-1) \times w$。使$y(t)$尽可能地跟随$W_r$，可以被建模为一个反馈控制问题。$w$和$y(t)$分别是系统的输入和输出,并且控制误差是$e(t) = W_q - y(t)$，由于$y(t)$与$\varphi(t)$的关系是由基于M/M/N的前馈控制器描述的，它是非线性的，设计一个反馈控制器将$e(t)$直接转化为适当的控制输入$\varphi(t)$是非常复杂的。

##### 5.3.1 基于线性模型的抽象化

&emsp;&emsp;本文研究了一个抽象的线性模型以简化分析。如图3所示，如果调整比率$w$对等待时间预期变化的函数可以建立。通过给函数一个平均等待时间的预期变化$u(t)$可以获得一个$w$。然后，$\varphi(t)$可以通过基于前馈控制器资源更新的$w$更新。如果建立的调整比例$w$与变化的等待时间的函数是准确的，那么网络应用的实际平均等待时间将根据$u(t)$来变化。因此，该系统可以被抽象为一个简单的线性模型
$$
y(t+1) = y(t) +u(t)
$$
其中，$u(t)$是作为控制输入的平均等待时间的预期变化。然后，可以在这个线性模型的基础上建立反馈控制器。在下面的章节中，提出了改变等待时间的$w$的函数和一个比例控制器。

##### 5.3.2 调整率$w$对预期等待时间变化的函数$u(t)$

&emsp;&emsp;给定一个实时平均等待时间$y(t)$和当前的资源容量，根据排队模型可以得到一个真实的到达率$\lambda_{real}$。同时，给定一个目标等待时间$W_d = y(t)+u(t)$（$u(t)$是等待时间的预期变化）和当前资源容量，目标到达率$\lambda_{dest}$也可以用排队模型生成。比值$w = \frac{\lambda_{real}}{\lambda_{dest}}$描述了在当前资源能力下，实际到达率应调整多少，以使等待时间从$y(t)$变为$W_d$。在本文中，比率$w$被用来近似地描述测量的到达率应该调整多少，以改变租用的资源量，以赶上一个目标的等待时间$W_d$。

&emsp;&emsp;然而，给定$y(t)$和$R$，使用M/M/N排队模型计算$\lambda_{real}$是很复杂的，因为直接从$\lambda$到方程(1)，(2)和(3)中描述的$W_q$，推导出原函数的反函数是十分复杂的。相反，M/M/1的类似反函数可以很容易地推导出来，如下所示。M/M/1的预期等待时间$W_q$到$\lambda$的函数是:
$$
W_q = f(\lambda) = \frac{\lambda}{\mu_t(\mu_t-\lambda)}
$$
其中$\mu_t$是所有虚拟机的总处理率。$f$的反函数为:
$$
\lambda = f^{-1}(W_q) = \frac{\mu_t^2W_q}{1+\mu_tW_q}
$$
因此，为了简化，比率$w$是用M/M/1而不是M/M/N计算的，以下是建立调整率$w$与预期等待时间$u(t)$变化的函数，带入Wd=y(t)+u(t)：
$$
w = \frac{\lambda_{real}}{\lambda_{dest}}\\
=\frac{f^{-1}(y(t))}{f^{-1}(W_d)}\\=\frac{\mu^2_ty(t)}{1+\mu_ty(t)}/\frac{\mu^2_tW_d}{1+\mu_tW_d}\\
=\frac{y(t)(1+\mu_t(y(t)+u(t)))}{(y(t)+u(t))(1+\mu_ty(t))}
$$

##### 5.3.3 基于双阈值的比例控制器设计

&emsp;&emsp;在大多数现有方法中，输出误差是实时等待时间和参考等待时间之间的偏差。然而，由于虚拟机只能以离散的数量被租用或释放，虚拟云数据中心的总容量只能以粗粒度的规模变化，输出误差可能始终存在。传统计算方法的输出误差通常会导致系统的波动。 因此，采用基于双阈值的方法计算输出误差。输出误差$e(t)$被定义为$y_t$与$W_r \times lower\_thr$到$W_r \times upper\_thr$区间的下限或上限阈值之差。当$y_t$在该区间内时，$e(t)$被定义为0，以避免进一步控制可能导致更大的输出误差。
$$
e(t) = \begin{cases}
W_r \times lower\_thr - y(t),y(t)<W_r \times lower\_thr \\
W_r \times upper\_thr -y(t),y(t)>W_r \times upper\_thr\\
0,Otherwise
\end{cases}
$$
&emsp;&emsp;所提出的抽象线性模型假设控制输入$u(t)$将对输出产生直接的附加影响，这就简化了控制器的设计。基于基于双阈值的输出误差计算方法，采用比例控制器，即$u(t)=K_p×e(t)$，$K_p$是控制增益。线性模型的传递函数为:
$$
\frac{Y}{U} = \frac{1}{z-1}
$$
&emsp;&emsp;比例控制器的转移函数是：
$$
\frac{U}{E} = K_p
$$
&emsp;&emsp;整个反馈控制系统的转移函数是:
$$
\frac{Y}{W} = \frac{K_p\frac{1}{z-1}}{1+K_p\frac{1}{z-1}}=\frac{K_p}{z-1+K_p}
$$
&emsp;&emsp;整个反馈控制系统的极点是$1-K_p$。根据沉降时间和过冲要求，$K_p$的选择将基于极点放置法(PPM)，并在参数调整部分进行实验。

##### 5.3.4 基于双阈值和排队模型的反馈控制器的描述

&emsp;&emsp;算法3是对所提出的双阈值和基于排队模型的反馈控制方法(TFBC)的正式描述。首先，由公式(8)得到$e(t)$。然后，$u(t)$是等待时间的预期变化，它是$e(t)$和控制增益$K_p$的乘积。调整后的目标平均等待时间$W_d$是$y(t)$和$u(t)$之和。获得目标平均等待时间$W_d$所需的调整比率$w$是用公式(7计算的。$w$被限制在[$w^{upper},w^{lower}$]的区间内，以避免太大规模的调整引起波动。最后，通过乘以比率$w$来更新$\varphi(t)$。

![Unequal-interval_Algorithm_3](image\Unequal-interval_Algorithm_3.png)

#### 5.4 不等间隔的合作策略

&emsp;&emsp;对于控制问题，需要对输入进行频繁的调整，以应对动态工作负荷产生的输出误差。然而，输入调整通常会有延迟生效，例如，新申请的虚拟机大约需要1到2分钟才能可用，而虚拟机最多需要1小时才能真正释放。对输入的调整过于频繁，很可能导致过度控制，例如，在调整生效之前租用或释放多余的虚拟机。因此，确定两个控制动作之间的时间间隔（称为控制间隔）是至关重要的。提出了一种基于两个控制器的松散耦合结构的不等间隔的前馈和反馈协作方法。这种协作方法考虑到云计算虚拟机的租用和释放延迟，分别给反馈和前馈控制器分配了不同的控制间隔。调用反馈控制器的时间间隔应长于虚拟机准备时间，以使新租用的虚拟机生效。同时，在调用反馈控制器之前，应该检查最后一个虚拟机释放动作是否已经生效，也就是说，确定要释放的虚拟机真的被释放了。虚拟机释放状态检查方法(RC)如下。对于一个虚拟机组，如果任何一个虚拟机在其租用时间结束时被释放，使得该组的容量低于$Q$，这意味着没有虚拟机可以再被释放以满足容量$Q$。 如果所有组的虚拟机都不能被释放，这意味着之前的控制动作所确定的需要释放的虚拟机真的都被释放了。相反，前馈控制器可以比反馈控制器更频繁地被调用，以快速响应工作量的变化，因为两个控制器是松散耦合的，前馈控制器可以暂时很好地单独工作。

#### 5.5 不等间隔松散耦合控制方法的描述

&emsp;&emsp;基于所提出的松散耦合的前馈和反馈控制器以及不等间隔的协作策略，所提出的基于不等间隔的松散耦合控制方法(UCM)在算法4中得到了正式描述。前馈控制器的主要目标是调整所需的虚拟机容量，以应对工作负载的变化。因此，当$B_s = TRUE$(快速前馈被启用)时，前馈控制器在每个工作量采样间隔$\alpha$(例如,1分钟)被调用，以快速响应工作量变化。基于分钟的快速前馈(𝛼=60秒)被称为MF。每隔$\beta$(例如，300)秒，检查反馈控制器是否可以被调用。$\beta$应该大于虚拟机的准备时间，并且通常要比$\alpha$长很多。当系统供应不足时$(y(t)>W_r)$，反馈控制器TFBC被直接调用。否则，当$B_c=TRUE$时，由RC检查虚拟机释放状态$B_r$。然后，如果$B_c =FALSE$(不检查虚拟机释放状态)或$B_r =TRUE$(虚拟机已经释放)，反馈控制器被调用。否则，反馈控制器不被调用。最后，由于提出的反馈和前馈控制器是松散耦合的，无论反馈控制器是否被调用，都会调用前馈控制器$QFC$和基于组的资源租用方法$$GFT$$。

![Unequal-interval_Algorithm_4](image\Unequal-interval_Algorithm_4.png)

### 6 效果评估

&ensp;&emsp;UCM和现有的算法首先在一个模拟环境中进行评估，该环境是用支持Spot虚拟机建模的$CloudSim$创建的。同时，还在一个由六个虚拟机组成的真实集群中对算法进行了比较，这些虚拟机由$Kubernetes$组织，借助容器和请求自动转发技术实现弹性资源配置。主节点是一台拥有四个2.6GHz英特尔i7-9750H虚拟处理器和2GB内存的虚拟机。四个拥有三个英特尔2.4GHz i5-6300或2.6GHz i7-9750H虚拟处理器和1GB内存的虚拟机是工作节点。 一个用于计算斐波那契数的Web应用程序以容器的形式部署在工作节点上。由于在一个虚拟机中创建更多的容器不会增加总容量，每个虚拟机只能容纳一个应用容器。工作者虚拟机通过在虚拟机上创建（或删除）应用程序的容器，动态地分配给（从）Web应用程序。主节点中的ingress-nginx-controller被用来转发属于当前应用的容器的请求。基于$Kubernetes$的资源管理方法也可用于管理从公共云租用的虚拟机。JMeter作为一个并发请求生成器。

&emsp;&emsp;由于维基百科的用户访问痕迹具有共同的波动特征，2007年9月和10月的用户访问痕迹被用作工作负载。由于原始跟踪数据每秒包含1500到3500个请求，为了加快模拟速度，对原始请求的大约5%进行随机抽样。由于维基百科的追踪具有明显的每周季节性模式，因此使用了2周不重叠的追踪，称为$CloudSim$评估的工作负载1和2。如表2所示，在$CloudSim$中模拟了八种具有不同配置和价格的亚马逊EC2现货和按需虚拟机。Spot虚拟机的真实价格由亚马逊EC2的接口获得，用于评估租赁成本。在真实的$Kubernetes$集群的实验中，每小时的访问痕迹被压缩为10分钟，以通过采样来加速评估。 而在$Kubernetes$集群上的实验，每种算法都持续了12小时。JMeter根据访问痕迹中每分钟的请求数生成请求。为了简化，$Kubernetes$集群中两种类型的虚拟机的价格分别被设定为每10分钟1个和2个。

&emsp;&emsp;首先，UCM与$GFT$方法进行了比较，后者是少数考虑到异构Spot虚拟机的工作之一。$GFT$所需的总资源容量R是最后一个𝜆m和平均请求长度（百万条指令）的乘法。$GFT$主要关注容错策略，没有考虑预测所需的虚拟机容量，以控制给定区间内的平均等待时间。因此，UCM与QT24进行了比较，后者使用基于M/M/N模型的前馈控制器来预测所需的虚拟机容量。因为QT不是为Spot虚拟机量身定做的，所以通过添加$GFT$作为容错策略来扩展它，扩展后的QT被称为$GFT$-FF。接下来，UCM与Wang等人提出的另一种基于不等式M/M/N排队模型的前馈方法UQueuing进行了比较。UCM还与EcoWare进行了比较，后者是一种经典的基于简单非线性模型的反馈控制方法。最后，UCM与Sha等人10提出的HC-FFB进行了比较，后者在控制传统服务器进程方面获得了良好的性能。HC-FFB应用G/G/N模型作为前馈控制，并应用基于排队模型衍生的线性模型的PI控制器作为反馈控制。由于基于不同排队模型的前馈控制的比较不是本文的主要关注点，为了公平比较，HC-FFB的G/G/N模型被QT24中使用的M/M/N取代。因为HC-FFB的设计是为了控制响应时间而不是等待时间，所以不能直接使用基于M/M/1建立的一阶线性模型，该模型描述了增加（减少）处理率的数量对减少（增加）输出响应时间的影响。本文建立一个类似的一阶线性模型来描述处理率的变化对平均等待时间变化的影响，具体如下。M/M/1的平均等待时间为：
$$
W_q = \frac{\lambda}{\mu^2_t - \mu_t\lambda}
$$
其中$\mu_t$和$\lambda$分别是处理和到达率。由于$\mu_t$与稳定状态下的$\lambda$相似，等待时间对$\mu_t$的一阶导数为:
$$
\frac{dW_q}{d\mu_t} = -\lambda(\frac{1}{\mu^2_t - \mu_t\lambda})^2(2\mu_t- \lambda)\\ \approx -\lambda(\frac{1}{\mu^2_t - \mu_t \lambda})^2(2\lambda - \lambda)\\=-(\frac{\lambda}{\mu^2_t -\mu_t\lambda})^2=-(W_q)^2
$$
&emsp;&emsp;然后，线性模型$dW_q = -(W_q)^2 \times d\mu_t$被用来建立一个$PI$反馈控制器。用$GFT$扩展的HC-FFB和新的基于线性模型的$PI$反馈控制器被称为HC-$GFT$-FFB。为了评估所提出的VM RC和基于分钟的快速前馈（MF）的性能，对表3中所示的UCM、HC-$GFT$-FFB、$GFT$、UQueuing和EcoWare的变体进行了比较。现有$GFT$的参数与现有工作一致，是f=1，dmargin=0.2，Nal=3，h=4。

<center>表2 亚马逊EC2的模拟虚拟机类型</center>

![Unequal-interval_Table2](image\Unequal-interval_Table2.png)

<center>表3 比较算法的细节</center>

![Unequal-interval_Table3](image\Unequal-interval_Table3.png)

&emsp;&emsp;由于网络应用的复杂性，真实的平均等待时间总是围绕着给定的参考等待时间Wr波动。因此，应选择适当的参考等待时间$W_r$以避免违反通常小于$W_{sla}$的$SLA$。在$CloudSim$中，假设在$SLA$中定义了$W_{sla}$=0.1秒和$k$=95，也就是说，95%的等待时间应小于0.1秒。较大的$W_r$增加了违反$SLA$的能力，而较小的$W_r$增加了虚拟机的租赁成本。在${0.005,0.01,0.02,0.04,0.08}$的不同值中，通过实验测试，选择了具有适当成本和等待时间的$W_r=0.02$秒。请求的长度是按照指数分布随机产生的，其平均值为2000 MI，这意味着在处理率为4000 MIPS的最小的虚拟机c4.L上处理需要0.5秒。虚拟机的准备时间，包括向公共云的请求时间被设定为150秒。到达率采样间隔和快速前馈调用间隔为$𝛼=60$秒，反馈控制间隔为$𝛽=300$秒。在真实的$Kubernetes$集群上的实验中，根据Fibonacci网络应用的特点和实验，选择了$W_{sla}=0.045$秒和$W_r=0.03$秒。通过实验，两类$Kubernetes$ Cluster的虚拟机上的请求处理率分别为20/s和40/s左右。而最快的虚拟机上一个请求的平均处理时间约为0.02秒。为了公平比较，平均等待时间是从所有算法的ingress-nginx-controller的平均响应时间中减去0.02秒得到的。因为容器可以在半分钟内分配给应用，所以控制间隔缩短为$𝛽=180$秒，并通过设置$B_s=FALSE$禁用快速前馈。

#### 6.1参数调整

&emsp;&emsp;UCM的P控制器和HC-$GFT$-FFB的PI控制器的控制增益是由PPM和实验评估共同决定的。根据PPM，控制系统的极点对稳定性、安顿时间和最大过冲有很大影响。极点应该在单位圆内，以使系统稳定，对于一阶系统来说，极点应该是正的，以避免过冲现象。由于网络系统的粗粒度容量调整规模和复杂性，满足上述PPM标准的候选极${0.9,0.7,0.5,0.3,0.1,0}$的实际性能通过实验进行评估。对于UCM，控制增益由$K_p=1$极产生，即$Kp∈{0.1,0.3,0.5,0.7,0.9,1}$。类似地，HC-$GFT$-FFB的PI控制器的控制增益也可以得到。

&emsp;&emsp;当平均等待时间(PAWT)大于0.1秒(用$PAWT[0.1,∞]$表示)的百分比大于95%时，意味着$CloudSim$模拟的$SLA$被违反了。较大的$PAWT[0.05,0.1]$意味着当有突然爆发的请求时，违反$SLA$的可能性较大。较大的$PAWT[0,0.005]$意味着更多的资源被租用，产生更高的租赁成本。因此，本文旨在将等待时间控制在一个理想的区间内，如$[0.005,0.05]s$，以节省租赁成本并同时保证$SLA$。图4A显示了我们的方法UCM-RC-M在$CloudSim$上不同$K_p$下的PAWT。总的来说，$K_p=1$的UCM-RC-M获得了最小的$PAWT[0.05,∞]=10.4%$。(6.3%和4.1%的总和)，并且所有UCM-RC-M的成本都相似。图4 B显示了不同极点的现有算法HC-$GFT$-FFB的PAWT，显示了极点=0.9的HC-$GFT$-FFB得到了最小的$PAWT[0.05,∞]$，为17%（8.3%和8.7%之和）。因此，对于UCM和HC-$GFT$-FFB，分别选择$K_p=1$和$pole=0.9$。尽管EcoWare-RC9的极点$𝛼$最初等于0.95，但在本文中，$𝛼$被设定为0.9，与HC-$GFT$-FFB一致。根据实验比较，对于$CloudSim$来说，选择 $lower\_thr=0.75, upper\_thr=1.25, 𝜔^{lower} = 0.95$ 和$ 𝜔^{upper} = 1.05$。对于$Kubernetes$集群，选择 $lower\_thr=0.5, upper\_thr=1, 𝜔^{lower} = 0.95$和$ 𝜔^{upper} = 2$。

![Unequal-interval_Fig_4](image\Unequal-interval_Fig_4.png)

<center>图4 UCM-RC-M和HC-GFT-FFB的平均等待时间和租赁费用的分布情况</center>

#### 6.2 CloudSim上的结果

&emsp;&emsp;图5 A-C显示了在$CloudSim$上使用工作负载1和2的比较算法的PAWTs和租赁成本。实验结果表明，现有的$GFT$和$GFT$-FF通常租用过多的资源，虚拟机租用成本最高，99.9%以上的平均等待时间都小于0.005 s。因为$GFT$和$GFT$-FF的总容量仅根据历史工作量或基于排队模型的前馈控制器确定，而不对输出误差作出反应。相反，所有其他带有反馈控制器的方法可以通过尝试租用适当数量的资源，使更多的平均等待时间保持在期望的区间$[0.005,0.05]s$内，从而大大降低租用成本。UCM-RC和HC-$GFT$-FFB-RC的PAWT[0.05,∞]远小于UCM-NRC和HC-$GFT$-FFB-NRC。例如，HC-$GFT$-FFB-RC的PAWT[0.05,∞]为17%（8.3%和8.7%之和），远远小于工作负载1上传统HC-$GFT$-FFB-NRC的31.6%（6.8%和24.8%之和）。这说明传统的HC-$GFT$-FFB-NRC大大违反了$SLA$(95%不大于0.1秒)，不适合控制按小时计价的虚拟机的情况，尽管HC-$GFT$-FFB-NRC有反馈和前馈控制器。而虚拟机RC大大改善了现有HC-$GFT$-FFB-NRC的性能。同样，通过应用RC，我们的方法UCM-RC的PAWT[0.05,∞]与UCM NRC相比大大降低。例如，在工作负荷2上，PAWT[0.05,∞]从UCM-NRC的28.5%（8.4%和20.1%之和）降至UCM-RC的11.7%（7.5%和4.2%之和）。

![Unequal-interval_Fig_5](image\Unequal-interval_Fig_5.png)

<center>图5 在CloudSim和Kubernetes集群上比较算法的平均等待时间和租赁成本的分布情况</center>

&emsp;&emsp;实验结果还表明，UCM-RC的PAWT[0.05,∞]比HC-$GFT$-FFB-RC的低。例如，在工作负载1上，UCM-RC的PAWT[0.05,∞]为11.7%（7%和4.7%之和），小于HC-$GFT$-FFB-RC的17%（8.3%和8.7%之和），也就是说，UCM-RC在避免违反$SLA$方面更为强大。此外，UCM-RC-M的PAWT[0.05,∞]比UCM-RC小很多。例如，UCM-RC-M的PAWT[0.05,∞]为10.4%（6.3%和4.1%之和），小于UCM-RC在Workload 1上的11.7%（7%和4.7%之和）。它证明了快速前馈（MF）有助于降低PAWT[0.05,∞]。同时，与UCM-RC和UCM-RC-M相比，HC-$GFT$-FFB-RC的PAWT[0,0.005]要大得多，也就是说，HC-$GFT$-FFB-RC有时会浪费更多资源。相反，UCM-RC和UCM-RC-M使更多的平均等待时间聚集在期望的区间[0.005,0.05]s，百分比分别为74.1%和69.4%，大于工作负载1上HC-$GFT$-FFB-RC的56.5%。 同时，UCM-RC、UCM-RC-M和HC-$GFT$-FFB-RC的租金成本相似。 这说明我们的方法UCM-RC和UCM-RC-M比HC-$GFT$-FFB-RC更稳定地控制系统，而租赁成本相似。例如，图6 A显示了700个控制步骤的工作负载和虚拟机容量，表示随着工作负载的变化，UCM-RC-M的总虚拟机容量与HC-$GFT$-FFB-RC相比变化更稳定。因此，如图6 B-C所示，HC-$GFT$-FFB-RC有许多连续的平均等待时间小于0.005秒，而UCM-RC-M的平均等待时间几乎均匀地分布在参考点0.02秒左右。因为提出的基于M/M/1的TFBC可以适当地更新到达率调整系数，以应对环境和工作量的变化，比现有的基于M/M/1衍生的线性模型反馈控制器更稳定。图6还表明，UCM-RC-M的总虚拟机容量不仅稳定而且经常更新。这是因为松散耦合的前馈和反馈架构允许单独和更频繁地调用前馈控制器，以更快地对工作负载的变化做出反应。

![Unequal-interval_Fig_6](image\Unequal-interval_Fig_6.png)

<center>图6 700个控制步骤内的工作负载和虚拟机容量样本</center>

#### 6.3 真实Kubernetes集群上的结果

&emsp;&emsp;图5 D显示了在真实的$Kubernetes$集群上比较算法的PAWTs和租赁成本。$GFT$和$GFT$-FF没有在真实的集群上进行评估，因为在$CloudSim$上表现不佳。UCM-RC的PAWT[0,0.045]比其他所有算法大91.75%（81.82%和9.93%之和），也就是说，UCM-RC得到的平均等待时间比$W_{sla}=0.045s$大的百分比最小。同时，除了HC-$GFT$-FFB-RC，UCM-RC的租金成本是最低的。这些都证明了UCM-RC可以通过基于TFBC的系数调整来适当地调整资源，对真实集群进行辅助。UCM-RC和HC-$GFT$-FFB-RC在真实集群上的比较结果与$CloudSim$上的结果一致。尽管EcoWare-RC的PAWT[0,0.045]与UCM-RC的91.37%接近，但EcoWare-RC的租赁成本为374，比UCM-RC的成本高31%。原因是EcoWare-RC对小于$W_r$的等待时间反应过快，导致更多更大的违反$SLA$的行为，并且由于反比例性能模型的特点，导致更高的租赁成本。Uqueuing-RC的PAWT[0,0.045]为90.38%，表明与UCM-RC和EcoWare RC相比，W$SLA$的平均等待时间更大，Uqueuing-RC的租用成本为337，远远高于UCM-RC的284。原因是，由于系统的复杂性和对虚拟机处理率的不准确估计，Uqueuing-RC的不等式M/M/N模型与实际系统之间存在不可避免的偏差。尽管当系统变得不稳定时，Uqueuing-RC会考虑到实时排队长度而迅速做出反应，但在系统稳定时，如果这种偏差是由于模型不准确造成的，Uqueuing-RC就不能修正估计的等待时间与实际等待时间之间的偏差。

### 7 结论和未来工作

&emsp;&emsp;为了降低虚拟机的租用成本，同时保证服务水平和稳健性，我们提出了一种混合控制方法UCM，它利用了基于排队模型的松散耦合控制器、基于不等间隔的协作方法和现有的$GFT$策略的优势。实验结果表明，反馈控制使更多的平均等待时间保持在一个合理的区间内，以节省租金成本。而我们的方法与$HC-GFT-FFB-NRC$和$HC-GFT-FFB-RC$相比，在$CloudSim$和$Kubernetes$集群上，在相似的租用成本下，将大于$SLA$的等待时间的百分比从约24.7%-24.8%和23.2%分别降低到4.1%-4.2%和9.6%。与EcoWare-RC和Uqueuing-RC相比，我们的方法获得了较低的$SLA$违反率和18.6%至31%的租赁成本。这些实验结果证明，所提出的虚拟机释放状态检查有助于避免对具有间隔价格的云虚拟机的网络应用进行过度控制。与现有的排队模型派生的线性模型相比，所提出的对等待时间预期变化的调整比率函数更准确地描述了Web系统。前馈和反馈控制器的松散耦合结构允许单独和频繁地调用前馈控制器，这有助于对工作量的变化做出快速反应。有希望的未来工作是将区间定价模型意识到的反馈方法应用于控制其他具有MapReduce或基于Directed-Acyclic-Graph任务的复杂云应用程序的服务质量。